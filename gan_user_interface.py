# -*- coding: utf-8 -*-
"""GAN_User_Interface.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6-abqJAtlb0O3h4jLMSz3dE8ktLMyRV

#User Interface for Controlling Features of Generated Faces

Beginning of source code for an app/user interface that will allow user to generate faces and control specific features of the face.
"""

!pip install anvil-uplink
import anvil.server
anvil.server.connect("35E26GPZIK7KR7BLS3SBP66L-Z7KN2ZG6G7EQCSR2")

# #===============writing html file directly in colab===============
# %%writefile templates/index.html
# <!DOCTYPE html>
# <html >
# <!--From https://codepen.io/frytyler/pen/EGdtg-->
# <head>
#   <meta charset="UTF-8">
#   <title>SPAM_API</title>
#   <link href='https://fonts.googleapis.com/css?family=Pacifico' rel='stylesheet' type='text/css'>
# </head>
# <body>
#  <div class="login">
#      <h1>Spam detection</h1>
#      <!-- Main Input For Receiving Query to our ML -->
#      <form action="{{ url_for('predict')}}"method="post">
#      <textarea id="styled" name="message" rows="6" cols="50" placeholder="Enter Your Message Here" required="required" ></textarea>
#      <button type="submit" class="btn btn-primary btn-block btn-large">Predict</button>
#     </form>
#    <br>
#    <br>
#    {{ prediction_text }}
# </div>
# </body>
# </html>
# # #========here is the code for using linux cmd in colab=============
# # #write the same html file as above
# # !cd templates
# # !cat > index.html
# # #manually open the file and write the html code
# # #================using sys cmd in python ========================
# # file = open("/templates/index.html,"w")
# # html_code = """
# #      write your html code here
# #      """
# # file.writelines(html_code) 
# # file.close()

# %%writefile app.py
# #importing libraries
# import numpy as np
# from flask import Flask, request, jsonify, render_template
# from flask_ngrok import run_with_ngrok
# import pickle
# #creating the flask object
# app = Flask(__name__)
# run_with_ngrok(app)
# #loading the model weights
# filename = r"/content/new_nlp_model.pkl"
# clf = pickle.load(open(filename, 'rb'))
# cv=pickle.load(open(r"/content/new_tranform.pkl",'rb'))
# #create routes
# @app.route('/')
# def home():
#     return render_template('index.html')
# @app.route('/predict',methods=['POST'])
# def predict():
#     '''
#     For rendering results on HTML GUI
#     '''
#     if request.method == 'POST':
#         message = request.form['message']
#         data = [message]
#         vect = cv.transform(data).toarray()
#         my_prediction = clf.predict(vect)
#         if my_prediction == 1:
#             output = "a Spam"
#         elif my_prediction == 0:
#             output = "Not a Spam"
    
#     outputs = 'This email is '+output
#     return render_template('index2.html', prediction_text=outputs , value=message)
# if __name__ == "__main__":
#     app.run()

"""##Setup
Setting up correct runtime, cloning stylegan2, and defining necessary funtions for face generation.
"""

# Commented out IPython magic to ensure Python compatibility.
# Run this for Google CoLab (use TensorFlow 1.x)
# %tensorflow_version 1.x

!git clone https://github.com/NVlabs/stylegan2.git

!ls /content/stylegan2/

import sys
sys.path.insert(0, "/content/stylegan2")

import dnnlib

# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.
#
# This work is made available under the Nvidia Source Code License-NC.
# To view a copy of this license, visit
# https://nvlabs.github.io/stylegan2/license.html

import argparse
import numpy as np
import PIL.Image
import dnnlib
import dnnlib.tflib as tflib
import re
import sys

import pretrained_networks

#----------------------------------------------------------------------------

def expand_seed(seeds, vector_size):
  result = []

  for seed in seeds:
    rnd = np.random.RandomState(seed)
    result.append( rnd.randn(1, vector_size) ) 
  return result

def generate_images(Gs, seeds, truncation_psi, prefix):
    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]

    Gs_kwargs = dnnlib.EasyDict()
    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)
    Gs_kwargs.randomize_noise = False
    if truncation_psi is not None:
        Gs_kwargs.truncation_psi = truncation_psi

    for seed_idx, seed in enumerate(seeds):
        print('Generating image for seed %d/%d ...' % (seed_idx, len(seeds)))
        rnd = np.random.RandomState(0)
        tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]
        images = Gs.run(seed, None, **Gs_kwargs) # [minibatch, height, width, channel]
        path = f"/content/{prefix}-{seed_idx+1}.png"
        PIL.Image.fromarray(images[0], 'RGB').save(path)

# sc = dnnlib.SubmitConfig()
# sc.num_gpus = 1
# sc.submit_target = dnnlib.SubmitTarget.LOCAL
# sc.local.do_not_copy_source_files = True

# sc.run_desc = 'generate-images'
network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'

# dnnlib.tflib.init_tf() # ??

print('Loading networks from "%s"...' % network_pkl)
_G, _D, Gs = pretrained_networks.load_networks(network_pkl)
vector_size = Gs.input_shape[1:][0]

"""##Import Latent Directions

Import pre-trained latent directions from https://twitter.com/robertluxemburg/status/1207087801344372736
"""

from pathlib import Path

def get_control_latent_vectors(path):
    files = [x for x in Path(path).iterdir() if str(x).endswith('.npy')]
    latent_vectors = {f.name[:-4]:np.load(f) for f in files}
    return latent_vectors

# only run once
!wget 'https://hostb.org/NCM/stylegan2directions.zip'
!unzip stylegan2directions.zip

latent_controls = get_control_latent_vectors('stylegan2directions') # need to get from somewhere else
len(latent_controls), latent_controls.keys(), latent_controls['age'].shape

"""##Generate One Random Face"""

import cv2 
from google.colab.patches import cv2_imshow
import random

def show_img(latent):
  img = generate_images(Gs, latent, 0.5, "image")

  img = cv2.imread('/content/image-1.png')   
  cv2_imshow(img)
  
  # return img # ??

def generate_latent(seed=random.randrange(0,2**32 - 1)):

  seed = seed
  vector_size = 512
  original_latent = expand_seed([seed], vector_size)
  
  return original_latent

@anvil.server.callable
def generate_random_and_show():
  latent = generate_latent()
  show_img(latent)
  return latent

# latent = generate_latent(2981344)
# img = show_img(latent)

"""## Manipulate Latent Vector of Original Image"""

def manipulate_vector(original_latent, age=0, gender=0, smile=0, pitch=0, roll=0, 
                      yaw=0, eye_eyebrow_distance=0, eye_distance=0, eye_ratio=0, 
                      eyes_open=0, nose_ratio=0, nose_tip=0, nose_mouth_distance=0, 
                      mouth_ratio=0, mouth_open=0, lip_ratio=0):
  new_latent = original_latent + latent_controls['age']*age + latent_controls['gender']*gender + latent_controls['smile']*smile + latent_controls['pitch']*pitch + \
   latent_controls['roll']*roll + latent_controls['yaw']*yaw + latent_controls['eye_eyebrow_distance']*eye_eyebrow_distance + latent_controls['eye_distance']*eye_distance + latent_controls['eye_ratio']*eye_ratio
  # finish this
  return new_latent

@anvil.server.callable
def manipulate_and_show(original_latent, age=0, gender=0):
  new_latent = manipulate_vector(original_latent, age=age, gender=gender)
  show_img(new_latent)
  return new_latent

# # new_latent = original_latent + latent_controls['gender']*40 + latent_controls['age']*0
# new_latent = manipulate_vector(latent, gender = 40)

# show_img(new_latent)

# import cv2 
# from google.colab.patches import cv2_imshow

# # 8227
# for i in range(0,10):
#   z = [i for j in range(512)]
#   print(z)
#   # seeds = expand_seed([z], vector_size)
#   generate_images(Gs, [np.array([z])], 0.5, "image")
#   img = cv2.imread('/content/image-1.png')   
#   cv2_imshow(img)

# for i in range(0,10):
#   z = 0+i
#   print(i)
#   seeds = expand_seed([z], vector_size) + latent_controls["age"]*10
#   generate_images(Gs, seeds, 0.5, "image")
#   img = cv2.imread('/content/image-1.png')   
#   cv2_imshow(img)

anvil.server.wait_forever()